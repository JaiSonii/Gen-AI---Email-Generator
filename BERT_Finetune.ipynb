{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jaius\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "R1omANl9cEtA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers datasets accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JcvntXrCcGzh",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaius\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_text': 'Generative AI Specialist, Blackbelt, Google Cloud share link link Copy link email email Email a friend corporate_fare Google place Bengaluru, Karnataka, India bar_chart bar_chart Mid Mid Mid Experience driving progress, solving problems, and mentoring more junior team members; deeper expertise and applied knowledge within relevant area. Apply share link link Copy link email email Email a friend Minimum qualifications: Preferred qualifications: About the job As a Generative Artificial Intelligence (AI) Specialist, you will work with Product Development and Technical Sales teams as an Generative AI subject matter expert to bring Google Cloud AI products to customers and partners. In this role, you will help prospective customers and partners understand the power of Google AI, explain technical features, help customers design architectures, build AI powered applications, and problem-solve any potential roadblocks. You will also have the opportunity to help customers leverage Google Cloud’s Generative AI services, including Large Language Models and specialized Machine Learning (ML) hardware developed by Google, called Tensor Processing Unit. Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems. Responsibilities Work with the team to identify and qualify business opportunities, understand key customer technical objections, and develop the strategy to resolve technical blockers. Provide AI expertise to support the technical relationship with Google’s customers, manage product and solution briefings, create demos, proof-of-concept work, and partner directly with product management to prioritize solutions impacting customer adoption to Google Cloud. Recommend integration strategies, enterprise architectures, platforms, and application infrastructure required to implement a complete solution on Google Cloud. Support developers, creators, and enterprises to leverage Google’s Generative Language APIs so they can build their own AI products in the future. Travel to customer sites, conferences, and other related events as needed. Google is a global company and, in order to facilitate efficient collaboration and communication globally, English proficiency is a requirement for all roles unless stated otherwise in the job posting. To all recruitment agencies: Google does not accept agency resumes. Please do not forward resumes to our jobs alias, Google employees, or any other organization location. Google is not responsible for any fees related to unsolicited resumes.', 'target_text': '{\"title\": \"Generative AI Specialist, Blackbelt, Google Cloud\", \"level\": \"Mid\", \"location\": \"Bengaluru, Karnataka, India\", \"description\": \"Our products are engineered for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping our customer developers, small and large businesses, educational institutions and government agencies. As part of an entrepreneurial team in this rapidly growing business, you will play a key role in understanding the needs of our customers and help shape the future of businesses of all sizes use technology to connect with customers, employees, and partners.\", \"key_qualifications\": \"Bachelor\\'s degree in Computer Science or equivalent practical experience. 9 years of experience serving in the capacity of a technical Solution Architect in a cloud computing environment or a customer-facing role. Experience with Large Language Models (LLMs), Open Source, Big Data, Machine Learning, and numerical programming frameworks. Experience with AI products, technologies, and infrastructure.\", \"preferred_qualifications\": \"Master\\'s degree in Computer Science or a related technical field. Experience with building AI and machine learning solutions, Machine Learning Operation frameworks (e.g., Kubeflow), and leveraging specific machine learning architectures (e.g., deep learning, LSTM, etc.). Experience architecting and developing software or infrastructure for scalable, distributed systems and with machine learning technologies. Understanding of AI Models, Large Language Models, and AI specialized infrastructure as it relates to AI trends and issues within businesses. Understanding of responsible AI practice. Ability to learn, understand, and work with new emerging technologies, methodologies, and solutions in the Cloud/IT technology space.\", \"responsibilities\": \"Work with the team to identify and qualify business opportunities, understand key customer technical objections, and develop the strategy to resolve technical blockers. Provide AI expertise to support the technical relationship with Google\\\\u2019s customers, manage product and solution briefings, create demos, proof-of-concept work, and partner directly with product management to prioritize solutions impacting customer adoption to Google Cloud. Recommend integration strategies, enterprise architectures, platforms, and application infrastructure required to implement a complete solution on Google Cloud. Support developers, creators, and enterprises to leverage Google\\\\u2019s Generative Language APIs so they can build their own AI products in the future. Travel to customer sites, conferences, and other related events as needed.\", \"company\": \"google\"}'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"vmal/jobs_dataset\")\n",
    "\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jw7hUB85fgr4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['source_text', 'target_text'],\n",
      "        num_rows: 5579\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eBJTVt-3fo0Q"
   },
   "outputs": [],
   "source": [
    "dataset = dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SNLHoxU0dSgo",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 5021/5021 [00:00<00:00, 8683.58 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 558/558 [00:00<00:00, 6785.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def format(example):\n",
    "  return {\n",
    "        \"input\": f\"Extract structured JSON from this job description page content:\\n{example['source_text']}\",\n",
    "        \"output\": example[\"target_text\"]  # Already a JSON string\n",
    "    }\n",
    "\n",
    "formatted = dataset.map(format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ftj8OTG0eS65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████| 5021/5021 [00:05<00:00, 928.10 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████| 558/558 [00:00<00:00, 952.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    input = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=1024)\n",
    "    output = tokenizer(batch[\"output\"], padding=\"max_length\", truncation=True, max_length=1024)\n",
    "    input[\"labels\"] = output[\"input_ids\"]\n",
    "    return input\n",
    "\n",
    "tokenized = formatted.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HYcupAuFeggg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 344,064 || all params: 77,305,216 || trainable%: 0.4451\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kA7YNX92e1Pg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "id": "fdy-DxFIfJMJ",
    "outputId": "f539eec6-2417-4c79-d618-3a3cd68f0b06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1368' max='1884' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1368/1884 2:03:23 < 46:36, 0.18 it/s, Epoch 2.18/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waRB5NUVq89x",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['test'][1]['source_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZpHD7FEh2C4"
   },
   "outputs": [],
   "source": [
    "input_text = dataset['test'][1]['source_text']\n",
    "\n",
    "inputs = tokenizer(f\"Extract structured JSON from this job description:\\n{input_text}\",\n",
    "                   return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "outputs = model.generate(input_ids=inputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqavzTPyoMZB"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"flan-jd-json\")\n",
    "tokenizer.save_pretrained(\"flan-jd-json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1c3tk55oR5I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
